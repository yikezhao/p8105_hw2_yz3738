Homework 2
================
Yike Zhao

This is my solution to HW2.

``` r
library(tidyverse)
```

    ## ── Attaching packages ────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ───────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
library(dplyr)
```

## Problem 1

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df =
  read_xlsx(
    "./Data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data for 2018 and 2017.

``` r
precip_2018 = 
  read_excel(
    "./Data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)

precip_2017 = 
  read_excel(
    "./Data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)
```

Now combine annual precipitation.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018,precip_2017)

left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # … with 14 more rows

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, include some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data.

## Problem 2

Read the NYC Transit data.

``` r
nyc_df = 
  read_csv(
   "./Data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
  ) %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, ada) %>%
  mutate(entry = ifelse(entry, yes, no))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

This dataset contains information of NYC transit. It contains line,
station\_name, station\_latitude, station\_longitude, route1, route2,
route3, route4, route5, route6, route7, route8, route9, route10,
route11, entry, vending, entrance\_type, ada. It includes 19 columns and
1868 rows. I think the original dataset isn’t very tidy.

``` r
nrow(distinct(nyc_df, line, station_name))
```

    ## [1] 465

``` r
nrow(distinct(filter(nyc_df, ada == "TRUE"), line, station_name))
```

    ## [1] 84

``` r
nrow(filter(nyc_df, vending == "NO")) / nrow(nyc_df)
```

    ## [1] 0.09796574

There are 465 distinct stations here, 84 stations are ADA compliant,
9.8% of station entrances / exits without vending allow entrance.

``` r
nyc_route =
  mutate(
  nyc_df,
  route8 = as.character(route8),
  route9 = as.character(route9),
  route10 = as.character(route10),
  route11 = as.character(route11)
  )
nyc_df_tidy = 
  pivot_longer(
    nyc_route,
    route1:route11,
    names_to = "route_name",
    values_to = "route_number"
  )
nrow(distinct(filter(nyc_df_tidy, route_number == "A"), line, station_name))
```

    ## [1] 60

``` r
nrow(distinct(filter(nyc_df_tidy, route_number == "A", ada == "TRUE"), line, station_name))
```

    ## [1] 17

60 distinct stations serve the A train. 17 of the stations are ADA
compliant.

## Problem 3

Read the pols-month data.

``` r
pols_month = 
  read_csv(
    "./Data/pols-month.csv"
  ) %>%
  janitor::clean_names() %>%
  separate(mon, c("year", "month", "day")) %>%
  select(-c(prez_dem, prez_gop,day))
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
pols_month_tidy = 
  pivot_longer(
    pols_month,
    gov_gop:rep_dem,
    names_to = "president",
    values_to = "value"
  )
```

Read the snp data.

``` r
snp_original = 
  read_csv(
    "./Data/snp.csv"
  ) %>%
  janitor::clean_names() %>%
  separate(date, c("month", "day", "year")) %>%
  select(-day) %>%
  relocate(year, month)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Read the unemployment data.

``` r
unemployment_original = 
  read.csv(
    "./Data/unemployment.csv"
  )%>%
  janitor::clean_names()

unemployment_tidy = 
  pivot_longer(
    unemployment_original,
    jan:dec,
    names_to = "month",
    values_to = "unemployment_rate"
  ) %>% 
  
mutate(month = recode(month, "jan" = "1", "feb" = "2",  "mar" = "3", "apr" = "4", "may" = "5","jun" = "6", "jul" = "7", "aug" = "8", "sep" = "9", "oct" = "10", "nov" = "11", "dec" = "12"))
```

Join the datasets together.

``` r
temp1 = left_join(pols_month_tidy,snp_original, by = "month")
five_thirty_eight = left_join(temp1, unemployment_tidy, by = "month")
five_thirty_eight
```

    ## # A tibble: 5,413,788 x 8
    ##    year.x month president value year.y close  year unemployment_rate
    ##    <chr>  <chr> <chr>     <dbl> <chr>  <dbl> <int>             <dbl>
    ##  1 1947   01    gov_gop      23 <NA>      NA    NA                NA
    ##  2 1947   01    sen_gop      51 <NA>      NA    NA                NA
    ##  3 1947   01    rep_gop     253 <NA>      NA    NA                NA
    ##  4 1947   01    gov_dem      23 <NA>      NA    NA                NA
    ##  5 1947   01    sen_dem      45 <NA>      NA    NA                NA
    ##  6 1947   01    rep_dem     198 <NA>      NA    NA                NA
    ##  7 1947   02    gov_gop      23 <NA>      NA    NA                NA
    ##  8 1947   02    sen_gop      51 <NA>      NA    NA                NA
    ##  9 1947   02    rep_gop     253 <NA>      NA    NA                NA
    ## 10 1947   02    gov_dem      23 <NA>      NA    NA                NA
    ## # … with 5,413,778 more rows

This dataset is consisted of three different datasets, pols-month, snp
and unemployment.It describes things like government polices,
unemployment rate and etc. It contains year.x, month, president, value,
year.y, close, year, unemployment\_rate. It includes 8 columns and
5413788 rows.
